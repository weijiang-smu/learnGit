{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 爬虫数据集筛选及保存\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 以前遇到过的函数\n",
    "\n",
    "def build_url(city_coding, year=None, month=None):\n",
    "    \"\"\"\n",
    "    创建网页链接\n",
    "    paramters:\n",
    "        city_coding: 城市名称(英文)\n",
    "        year: 年份\n",
    "        month: 月份\n",
    "    return:\n",
    "        url: 可访问的链接\n",
    "    \"\"\"\n",
    "    BASE = 'http://www.tianqihoubao.com/aqi/'\n",
    "    city_base_url = BASE + '{}.html'\n",
    "    city_date_base_url = BASE + '{}-{}{}.html'\n",
    "    \n",
    "    if year is not None and month is not None:\n",
    "        month = str(month) if month >= 10 else '0' + str(month)\n",
    "        return city_date_base_url.format(city_coding, year, month)\n",
    "    else:\n",
    "        return city_base_url.format(city_coding)\n",
    "\n",
    "\n",
    "def parse(url, city_name):\n",
    "    \"\"\"\n",
    "    抓取网页信息\n",
    "    parameters:\n",
    "        url: 需要抓取的网页链接\n",
    "        city_name: 城市名称(用于数据标识)\n",
    "    returns:\n",
    "        result: 抓取的信息\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "        \n",
    "        soup = BeautifulSoup(html)\n",
    "        data_table = soup.table\n",
    "        \n",
    "        content = data_table.contents\n",
    "        \n",
    "        result = []\n",
    "        for index, c in enumerate(content[1::2]):\n",
    "                if index == 0:\n",
    "                    result.append(tuple(['城市'] + c.text.split()))\n",
    "                else:\n",
    "                    result.append(tuple([city_name] + c.text.split()))\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        if response.status_code == 403:\n",
    "            print('403 Forbidden! 抓取太快你被拉黑啦~')\n",
    "\n",
    "            \n",
    "def save(data, file):\n",
    "    # 完成数据保存到文件\n",
    "    # your code here\n",
    "    # 提示：用什么方法将数据写入文件？\n",
    "    with open(file,'w',encoding='utf-8') as f:   #直接选择写入,添加默认utf-8模式，以便正常打开\n",
    "        f.write(data)\n",
    "    \n",
    "    print('data saved in ', file)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datas = []\n",
    "    for i in range(1, 2):\n",
    "        url = build_url('hangzhou', 2019, i)\n",
    "        data = parse(url, '杭州')\n",
    "        datas.extend(data)\n",
    "    #print(str(data))    \n",
    "    # 只保留质量等级优 良 数据\n",
    "    # your code here\n",
    "    # 提示：用什么方法对数据进行筛选？\n",
    "    strm=''\n",
    "    for i in range(len(data)):   #判断第三个元素是否是‘良’，并将数据保存为str格式，保持数据直观性，每行末尾添加换行符\n",
    "        if data[i][2]=='良':\n",
    "            strm+=str(data[i])+'\\n'  \n",
    "    data = strm[:-1]             #将最后一行换行符去掉\n",
    "    \n",
    "    # 保存数据\n",
    "    save(data, './data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 西瓜数据集保存及读取\n",
    "\n",
    "#添加编号列，并将数据集写入到machine_learning.csv文件，使用pandas读取验证文件是否有效(无错即可)。\n",
    "#添加一条记录，青绿 硬挺 浊响 稍糊 平坦 硬滑 0.666 0.111 是\n",
    "#再使用普通文件读取将数据集读取出来，列名读取到columns，数据(带编号)读取到datalist\n",
    "#在所有数据中过滤出色泽='浅白'的数据\n",
    "#在所有数据中过滤出密度大于0.5的数据\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dataset = \\\n",
    "\"\"\"色泽 根蒂 敲声 纹理 脐部 触感 密度 含糖率 好瓜\n",
    "青绿 蜷缩 浊响 清晰 凹陷 硬滑 0.697 0.460 是\n",
    "乌黑 蜷缩 沉闷 清晰 凹陷 硬滑 0.774 0.376 是\n",
    "乌黑 蜷缩 浊响 清晰 凹陷 硬滑 0.634 0.264 是\n",
    "青绿 蜷缩 沉闷 清晰 凹陷 硬滑 0.608 0.318 是\n",
    "浅白 蜷缩 浊响 清晰 凹陷 硬滑 0.556 0.215 是\n",
    "青绿 稍蜷 浊响 清晰 稍凹 软粘 0.403 0.237 是\n",
    "乌黑 稍蜷 浊响 稍糊 稍凹 软粘 0.481 0.149 是\n",
    "乌黑 稍蜷 浊响 清晰 稍凹 硬滑 0.437 0.211 是\n",
    "乌黑 稍蜷 沉闷 稍糊 稍凹 硬滑 0.666 0.091 否\n",
    "青绿 硬挺 清脆 清晰 平坦 软粘 0.243 0.267 否\n",
    "浅白 硬挺 清脆 模糊 平坦 硬滑 0.245 0.057 否\n",
    "浅白 蜷缩 浊响 模糊 平坦 软粘 0.343 0.099 否\n",
    "青绿 稍蜷 浊响 稍糊 凹陷 硬滑 0.639 0.161 否\n",
    "浅白 稍蜷 沉闷 稍糊 凹陷 硬滑 0.657 0.198 否\n",
    "乌黑 稍蜷 浊响 清晰 稍凹 软粘 0.360 0.370 否\n",
    "浅白 蜷缩 浊响 模糊 平坦 硬滑 0.593 0.042 否\n",
    "青绿 蜷缩 沉闷 稍糊 稍凹 硬滑 0.719 0.103 否\"\"\"\n",
    "\n",
    "# 将数据写入csv文件\n",
    "# your code here \n",
    "file = r'machine_learning.csv' # 文件名称，学员可修改或不修改\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "data_data = [ [x for x in y.split()] for y in dataset.split('\\n')[:] ] #将文本数据构造为数列\n",
    "\n",
    "bianhao = [[str(x) for x in range(len(dataset.split('\\n')[:])) ]]  # 生成编号数列\n",
    "bianhao = np.transpose(bianhao)                                    # 将数列转置\n",
    "bianhao[0] ='编号'                                                 # 将第一个元素替换为标题编号\n",
    "\n",
    "data_data = np.c_[bianhao,data_data]                               # 将编号列增加到原数列中\n",
    "\n",
    "with open(file, \"w\",encoding='utf-8', newline='') as f:            # 使用utf-8模式生成文件，并读取数列数据\n",
    "    # with open(birth_weight_file, \"w\") as f:\n",
    "    writer = csv.writer(f)   \n",
    "    writer.writerows(data_data)\n",
    "\n",
    "\n",
    "# 向csv文件中加入一条新的数据（数据已给出）\n",
    "# your code here\n",
    "# 注意每一行数据的间隔符号是什么\n",
    "inser_data = '18 青绿 硬挺 浊响 稍糊 平坦 硬滑 0.666 0.111 是'\n",
    "inser_data = [[x for x in inser_data.split()]]                    # 将字符串转换为数组\n",
    "\n",
    "with open(file, \"a\",encoding='utf-8', newline='') as f:           # 使用utf-8模式生成文件，并读取数列数据\n",
    "    # with open(birth_weight_file, \"w\") as f:\n",
    "    writer = csv.writer(f)   \n",
    "    writer.writerows(inser_data)\n",
    "    \n",
    "# 查看全体数据\n",
    "df = pd.read_csv(file)\n",
    "print(df.head())\n",
    "\n",
    "# 读取文件存储的数据\n",
    "# your code here\n",
    "# columns是指列标签\n",
    "# datalist指全体数据内容，每一行数据应为一个列表\n",
    "columns = list(df.head(0))                                    # 直接将首行转换为list\n",
    "\n",
    "df.iloc[:,0]=[str(x) for x in df.iloc[:,0]]                   # 将编号转换为字符串格式\n",
    "df.iloc[:,7]=[str(format(x,'.3f')) for x in df.iloc[:,7]]     # 将float数据取三位后转为为字符串格式\n",
    "df.iloc[:,8]=[str(format(x,'.3f')) for x in df.iloc[:,8]]     # 将float数据取三位后转为为字符串格式\n",
    "datalist = df.values.tolist()                                 # 将DataFrame格式转换为list\n",
    "\n",
    "# 验证数据信息是否相符\n",
    "print(columns==['编号', '色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '密度', '含糖率', '好瓜'])\n",
    "print(datalist[-1]==['18', '青绿', '硬挺', '浊响', '稍糊', '平坦', '硬滑', '0.666', '0.111', '是'])\n",
    "\n",
    "# 在所有数据中过滤出色泽='浅白'的数据\n",
    "# 在所有数据中过滤出密度大于0.5的数据\n",
    "# your code here\n",
    "\n",
    "df.loc[(df['色泽']=='浅白') & (df['密度'] >= '0.5')].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
